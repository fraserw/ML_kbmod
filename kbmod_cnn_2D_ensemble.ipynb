{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOPS for KBmod\n",
    "\n",
    "Based off the CNN developed for the first ML search of the New Horizons 2020 search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os, glob, sys\n",
    "import time\n",
    "\n",
    "import random\n",
    "\"\"\"Import the basics: numpy, pandas, matplotlib, etc.\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pyl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pickle\n",
    "\"\"\"Import keras and other ML tools\"\"\"\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv3D, Conv2D, MaxPool3D, MaxPool2D\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\"\"\"Import scikit learn tools\"\"\"\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "\"\"\"Import astropy libraries\"\"\"\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.visualization import interval\n",
    "\n",
    "from trippy import tzscale\n",
    "from trippy.trippy_utils import expand2d, downSample2d\n",
    "\n",
    "from convenience_utils import calc_ecliptic_angle\n",
    "\n",
    "from utils import shuffle\n",
    "\n",
    "from ensemble import convnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_data_type = 'float32'\n",
    "\n",
    "batch_size = 4096 # production used 128\n",
    "dropout_rate = 0.2\n",
    "test_fraction = 0.05\n",
    "select_bad_at_random = True\n",
    "badGoodRatio = 0.8*2.0#1.5\n",
    "bad_edge_enhancement = 0.002\n",
    "\n",
    "number_models = 5\n",
    "\n",
    "useMedForNans = False #otherwise zero is used\n",
    "useZscale = False\n",
    "\n",
    "\n",
    "shuffle_augment = True # shuffle bootstrapping augmentation\n",
    "double_flip = True # mirror vertically and horizontally augmentation\n",
    "add_noise = False\n",
    "noise_level=3.0\n",
    "\n",
    "\n",
    "#good ranges [19,21.5], [21, 23.5] [23.5,25.5], [25.5, 26.8]\n",
    "nukeBright = 26.0 # if set to a real value, all fainter planted source associations will be set to false\n",
    "nukeFaint = 26.8 # if set to a real value, all fainter planted source associations will be set to false\n",
    "dist_lim = 3.0 #association to planted source\n",
    "save_model_iteration = False\n",
    "\n",
    "useSampleWeights = True\n",
    "\n",
    "useTripletGrids = True\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"These are some of the flags.\"\"\"\n",
    "visits = ['03072', '03093']\n",
    "\n",
    "chips = []\n",
    "#for i in range(103,-1,-1):\n",
    "for i in range(104):\n",
    "    if i==9: continue\n",
    "    if i in [89]: continue\n",
    "    chips.append(str(i).zfill(3))\n",
    "#chips = ['031','050']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "First read in the data, and make it look like the data from the tutorial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4412754795592164\n",
      "102\n",
      "000 -1.18808801867614 0.0\n",
      "001 -0.09453831954545558 0.0\n",
      "002 0.8744980819135028 0.0\n",
      "003 1.8220850830578461 0.0\n",
      "004 -2.1419920431726283 0.0\n",
      "005 -1.0281424405745374 0.0\n",
      "006 -0.16998761512827165 0.0\n",
      "007 0.6729133575735556 0.0\n",
      "008 1.3647796264404044 0.0\n",
      "010 -1.7521249006635788 0.0\n",
      "011 -0.8132820671602755 0.0\n",
      "012 -0.18030994509453574 0.0\n",
      "013 0.4196113635608986 0.0\n",
      "014 1.0565958106580668 0.0\n",
      "015 1.6194045314479253 0.0\n",
      "016 178.5708055381495 180.0\n",
      "017 179.28830235636485 180.0\n",
      "018 179.833517837324 180.0\n",
      "019 0.3175541021766452 0.0\n",
      "020 0.7313349596999847 0.0\n",
      "021 1.2064609133897453 0.0\n",
      "022 178.10522623289881 180.0\n",
      "023 178.93396660255365 180.0\n",
      "024 179.45976272045675 180.0\n",
      "025 179.86591912393425 180.0\n",
      "026 0.1805464075787674 0.0\n",
      "027 0.49840039885517345 0.0\n",
      "028 0.7765309092959752 0.0\n",
      "029 1.0202150843358275 0.0\n",
      "030 178.62038902387246 180.0\n",
      "031 179.17062636917515 180.0\n",
      "032 179.59403802004894 180.0\n",
      "033 179.90643617324594 180.0\n",
      "034 0.0799578687083001 0.0\n",
      "035 0.23008868736247362 0.0\n",
      "036 0.3815383930413976 0.0\n",
      "037 0.4622364771625722 0.0\n",
      "038 179.07843527887323 180.0\n",
      "039 179.45840713730152 180.0\n",
      "040 179.73771484683465 180.0\n",
      "041 179.91378868276703 180.0\n",
      "042 0.02965853098149966 0.0\n",
      "043 0.07388376456485665 0.0\n",
      "044 0.06354975666858569 0.0\n",
      "045 -0.031103845202225176 0.0\n",
      "046 179.52922019699835 180.0\n",
      "047 179.78122715868162 180.0\n",
      "048 179.89453416996582 180.0\n",
      "049 179.95738771074488 180.0\n",
      "050 0.0 0.0\n",
      "051 -0.06741875751258361 0.0\n",
      "052 -0.28446567402936074 0.0\n",
      "053 -0.5022548979685233 0.0\n",
      "054 179.9973272800144 180.0\n",
      "055 180.04738547632883 180.0\n",
      "056 180.07321877165077 180.0\n",
      "057 179.9791593297475 180.0\n",
      "058 -0.10297487790594989 0.0\n",
      "059 -0.288203867960715 0.0\n",
      "060 -0.5651107180326668 0.0\n",
      "061 -0.9647304896860784 0.0\n",
      "062 180.52266971424956 180.0\n",
      "063 180.3991850054077 180.0\n",
      "064 180.25468974005295 180.0\n",
      "065 180.09370830697458 180.0\n",
      "066 -0.14714920294124786 0.0\n",
      "067 -0.4538658185978695 0.0\n",
      "068 -0.8549920173596116 0.0\n",
      "069 -1.4864798734313367 0.0\n",
      "070 180.98191635615106 180.0\n",
      "071 180.75245674623008 180.0\n",
      "072 180.48492294608812 180.0\n",
      "073 180.19633675270632 180.0\n",
      "074 -0.16769087716706144 0.0\n",
      "075 -0.5983887968294286 0.0\n",
      "076 -1.1699695148998783 0.0\n",
      "077 -1.9408908861548368 0.0\n",
      "078 181.19181043094463 180.0\n",
      "079 180.74583336749686 180.0\n",
      "080 180.2819340352665 180.0\n",
      "081 -0.18112631200649937 0.0\n",
      "082 -0.7319021330241241 0.0\n",
      "083 -1.4533147057833897 0.0\n",
      "084 181.666114507745 180.0\n",
      "085 181.02601502587268 180.0\n",
      "086 180.42011219422972 180.0\n",
      "087 179.78062497290253 180.0\n",
      "088 179.06437458069956 180.0\n",
      "090 182.18588003444356 180.0\n",
      "091 181.39387825512728 180.0\n",
      "092 180.61074486085488 180.0\n",
      "093 179.789938454981 180.0\n",
      "094 178.91964541505914 180.0\n",
      "095 177.77219128639027 180.0\n",
      "096 181.79616525751084 180.0\n",
      "097 180.8325935312042 180.0\n",
      "098 179.80919583053856 180.0\n",
      "099 178.6996099031898 180.0\n",
      "100 87.62485028341548 90.0\n",
      "101 91.7918628499445 90.0\n",
      "102 -88.15120963711033 270.0\n",
      "103 -92.42493032748598 270.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load the data\n",
    "#sns_frames = []\n",
    "n_edge_added = 0\n",
    "n_bad_total = 0\n",
    "\n",
    "reference_fits_images = []\n",
    "ecl_angles = []\n",
    "stamp_files = []\n",
    "kb_xys,fs = [],[]\n",
    "for i, c in enumerate(chips):\n",
    "    for j, v in enumerate(visits[:1]):\n",
    "        warps_path = f'/media/fraserw/SecondStage/Projects/kbmod/DATA/rerun/diff_warpCompare/deepDiff/{v}/HSC-R2/warps'\n",
    "        reference_fits_images.append(glob.glob(f'{warps_path}/{c}/DIFFEXP*fits')[0])\n",
    "        ecl_ang = calc_ecliptic_angle(reference_fits_images[-1])\n",
    "        ecl_angles.append(ecl_ang)\n",
    "        if c=='050':\n",
    "            ref_ecl_ang = ecl_ang\n",
    "            print(ref_ecl_ang)\n",
    "ecl_angles = np.array(ecl_angles)\n",
    "rots = (ref_ecl_ang-ecl_angles)*180./np.pi\n",
    "print(len(rots))\n",
    "corners = np.array([-270., -180., -90., 0., 90., 180., 270.])\n",
    "for i,r in enumerate(rots):\n",
    "    rot = corners[np.argmin(np.abs(r-corners))]\n",
    "    if rot<0: \n",
    "        rot+=360.\n",
    "    print(chips[i%len(chips)],r,rot)\n",
    "    rots[i] = rot/90.\n",
    "rots = rots.astype(np.int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03072 000 2497 7 2504\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03093 000 2614 3 2617\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 001 3642 3 3645\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 001 4363 1 4364\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03072 002 3471 1 3472\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03093 002 4264 4 4268\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03072 003 4064 4 4068\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03093 003 4033 6 4039\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 004 2157 1 2158\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03093 004 2997 4 3001\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03072 005 3331 2 3333\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 005 3668 6 3674\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 006 3478 4 3482\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03093 006 3911 5 3916\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03072 007 3767 1 3768\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03093 007 3906 6 3912\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 008 3782 8 3790\n",
      "Number good, bad, and number edge enhanced: 8 12 0\n",
      "03093 008 3879 5 3884\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03072 010 3210 7 3217\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03093 010 4202 6 4208\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 011 3441 3 3444\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 011 4204 4 4208\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03072 012 3069 3 3072\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 012 3841 6 3847\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 013 4277 6 4283\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03093 013 3505 6 3511\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 014 3982 3 3985\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 014 3516 6 3522\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 015 4025 6 4031\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03093 015 4213 9 4222\n",
      "Number good, bad, and number edge enhanced: 9 14 0\n",
      "03072 016 3680 9 3689\n",
      "Number good, bad, and number edge enhanced: 9 14 0\n",
      "03093 016 3970 3 3973\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 017 4010 4 4014\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03093 017 3892 6 3898\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 018 4071 7 4078\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03093 018 3601 4 3605\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03072 019 3569 5 3574\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03093 019 3454 3 3457\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 020 4493 9 4502\n",
      "Number good, bad, and number edge enhanced: 9 14 0\n",
      "03093 020 3988 4 3992\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03072 021 3836 6 3842\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03093 021 4233 8 4241\n",
      "Number good, bad, and number edge enhanced: 8 12 0\n",
      "03072 022 2574 0 2574\n",
      "Number good, bad, and number edge enhanced: 0 1 0\n",
      "03093 022 2933 3 2936\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 023 2949 0 2949\n",
      "Number good, bad, and number edge enhanced: 0 1 0\n",
      "03093 023 3669 6 3675\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 024 3228 2 3230\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 024 4284 6 4290\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 025 3852 9 3861\n",
      "Number good, bad, and number edge enhanced: 9 14 0\n",
      "03093 025 3342 8 3350\n",
      "Number good, bad, and number edge enhanced: 8 12 0\n",
      "03072 026 3997 7 4004\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03093 026 3449 5 3454\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03072 027 1231 5 1236\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03093 027 3633 5 3638\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03072 028 4019 7 4026\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03093 028 3852 12 3864\n",
      "Number good, bad, and number edge enhanced: 12 19 0\n",
      "03072 029 3149 3 3152\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 029 2785 3 2788\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 030 1922 2 1924\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 030 3795 9 3804\n",
      "Number good, bad, and number edge enhanced: 9 14 0\n",
      "03072 031 1122 2 1124\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 031 3959 8 3967\n",
      "Number good, bad, and number edge enhanced: 8 12 0\n",
      "03072 032 1945 0 1945\n",
      "Number good, bad, and number edge enhanced: 0 1 0\n",
      "03093 032 3928 2 3930\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03072 033 882 1 883\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03093 033 1732 7 1739\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03072 034 2037 5 2042\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03093 034 3297 2 3299\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03072 035 1954 2 1956\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 035 3671 6 3677\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 036 2191 4 2195\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03093 036 3988 4 3992\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03072 037 1482 4 1486\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03093 037 3951 8 3959\n",
      "Number good, bad, and number edge enhanced: 8 12 0\n",
      "03072 038 1966 3 1969\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 038 3969 4 3973\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03072 039 2226 3 2229\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 039 3496 8 3504\n",
      "Number good, bad, and number edge enhanced: 8 12 0\n",
      "03072 040 1814 3 1817\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 040 3840 3 3843\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 041 2275 5 2280\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03093 041 3172 5 3177\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03072 042 2045 5 2050\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03093 042 3726 9 3735\n",
      "Number good, bad, and number edge enhanced: 9 14 0\n",
      "03072 043 1000 6 1006\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03093 043 2839 4 2843\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03072 044 1466 5 1471\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03093 044 4136 13 4149\n",
      "Number good, bad, and number edge enhanced: 13 20 0\n",
      "03072 045 2049 7 2056\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03093 045 4315 10 4325\n",
      "Number good, bad, and number edge enhanced: 10 16 0\n",
      "03072 046 1939 2 1941\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 046 4150 9 4159\n",
      "Number good, bad, and number edge enhanced: 9 14 0\n",
      "03072 047 1838 5 1843\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03093 047 3749 1 3750\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03072 048 2480 3 2483\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 048 3623 1 3624\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03072 049 2047 2 2049\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 049 3392 7 3399\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03072 050 1804 2 1806\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 050 3638 9 3647\n",
      "Number good, bad, and number edge enhanced: 9 14 0\n",
      "03072 051 1651 6 1657\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03093 051 3939 6 3945\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 052 1998 5 2003\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03093 052 3926 9 3935\n",
      "Number good, bad, and number edge enhanced: 9 14 0\n",
      "03072 053 1523 2 1525\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 053 4277 5 4282\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03072 054 2054 3 2057\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 054 3852 3 3855\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 055 2231 4 2235\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03093 055 3854 2 3856\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03072 056 1888 5 1893\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03093 056 3887 8 3895\n",
      "Number good, bad, and number edge enhanced: 8 12 0\n",
      "03072 057 2184 2 2186\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 057 3522 3 3525\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 058 1972 3 1975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 058 3797 7 3804\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03072 059 1860 4 1864\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03093 059 3042 1 3043\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03072 060 2063 5 2068\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03093 060 4301 10 4311\n",
      "Number good, bad, and number edge enhanced: 10 16 0\n",
      "03072 061 1360 2 1362\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 061 4629 6 4635\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 062 1744 1 1745\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03093 062 3848 3 3851\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 063 2366 4 2370\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03093 063 3850 2 3852\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03072 064 2083 3 2086\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 064 3901 7 3908\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03072 065 2197 8 2205\n",
      "Number good, bad, and number edge enhanced: 8 12 0\n",
      "03093 065 3600 10 3610\n",
      "Number good, bad, and number edge enhanced: 10 16 0\n",
      "03072 066 2110 1 2111\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03093 066 4279 6 4285\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03072 067 1521 4 1525\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03093 067 4022 5 4027\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03072 068 1575 7 1582\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03093 068 4449 14 4463\n",
      "Number good, bad, and number edge enhanced: 14 22 0\n",
      "03072 069 1569 2 1571\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 069 4121 11 4132\n",
      "Number good, bad, and number edge enhanced: 11 17 0\n",
      "03072 070 1386 2 1388\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 070 3274 0 3274\n",
      "Number good, bad, and number edge enhanced: 0 1 0\n",
      "03072 071 2427 2 2429\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 071 3973 1 3974\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03072 072 2365 5 2370\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03093 072 3817 10 3827\n",
      "Number good, bad, and number edge enhanced: 10 16 0\n",
      "03072 073 1930 0 1930\n",
      "Number good, bad, and number edge enhanced: 0 1 0\n",
      "03093 073 3870 9 3879\n",
      "Number good, bad, and number edge enhanced: 9 14 0\n",
      "03072 074 4424 6 4430\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03093 074 3648 7 3655\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03072 075 2310 7 2317\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03093 075 4106 7 4113\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03072 076 2129 6 2135\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03093 076 4471 10 4481\n",
      "Number good, bad, and number edge enhanced: 10 16 0\n",
      "03072 077 1315 2 1317\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 077 3639 4 3643\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03072 078 2034 2 2036\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 078 4120 1 4121\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03072 079 2616 8 2624\n",
      "Number good, bad, and number edge enhanced: 8 12 0\n",
      "03093 079 4184 8 4192\n",
      "Number good, bad, and number edge enhanced: 8 12 0\n",
      "03072 080 1679 4 1683\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03093 080 3973 4 3977\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03072 081 2375 4 2379\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03093 081 4035 3 4038\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 082 2104 3 2107\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 082 3908 4 3912\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03072 083 2114 3 2117\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 083 4587 7 4594\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03072 084 2219 0 2219\n",
      "Number good, bad, and number edge enhanced: 0 1 0\n",
      "03093 084 4072 0 4072\n",
      "Number good, bad, and number edge enhanced: 0 1 0\n",
      "03072 085 2807 3 2810\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 085 4255 4 4259\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03072 086 1850 3 1853\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 086 4091 4 4095\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03072 087 1326 4 1330\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03093 087 3985 7 3992\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03072 088 2412 4 2416\n",
      "Number good, bad, and number edge enhanced: 4 6 0\n",
      "03093 088 3770 3 3773\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 090 1643 1 1644\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03093 090 2920 0 2920\n",
      "Number good, bad, and number edge enhanced: 0 1 0\n",
      "03072 091 2166 3 2169\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 091 4375 0 4375\n",
      "Number good, bad, and number edge enhanced: 0 1 0\n",
      "03072 092 1682 1 1683\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03093 092 4205 1 4206\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03072 093 1689 5 1694\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03093 093 3769 3 3772\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 094 1693 1 1694\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03093 094 3202 5 3207\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03072 095 1393 2 1395\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 095 3269 3 3272\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 096 1800 6 1806\n",
      "Number good, bad, and number edge enhanced: 6 9 0\n",
      "03093 096 4058 0 4058\n",
      "Number good, bad, and number edge enhanced: 0 1 0\n",
      "03072 097 2016 5 2021\n",
      "Number good, bad, and number edge enhanced: 5 8 0\n",
      "03093 097 4204 0 4204\n",
      "Number good, bad, and number edge enhanced: 0 1 0\n",
      "03072 098 2036 2 2038\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03093 098 4208 2 4210\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "03072 099 1970 7 1977\n",
      "Number good, bad, and number edge enhanced: 7 11 0\n",
      "03093 099 4110 3 4113\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03072 100 1267 1 1268\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03093 100 2189 1 2190\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03072 101 1131 3 1134\n",
      "Number good, bad, and number edge enhanced: 3 4 0\n",
      "03093 101 2366 1 2367\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03072 102 1254 1 1255\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03093 102 2472 0 2472\n",
      "Number good, bad, and number edge enhanced: 0 1 0\n",
      "03072 103 1082 1 1083\n",
      "Number good, bad, and number edge enhanced: 1 1 0\n",
      "03093 103 2535 2 2537\n",
      "Number good, bad, and number edge enhanced: 2 3 0\n",
      "(2255, 21, 21)\n",
      "Number of bad edge sources added: 0\n",
      "Number of total bad sources in sample 1360\n"
     ]
    }
   ],
   "source": [
    "gridType = ''\n",
    "if useTripletGrids:\n",
    "    gridType = '_tg'\n",
    "    \n",
    "counter = 0\n",
    "for i, c in enumerate(chips):\n",
    "    for j, v in enumerate(visits):\n",
    "        stamps_path = f'/media/fraserw/rocketdata/Projects/kbmod/stamps/{v}'\n",
    "        warps_path = f'/media/fraserw/SecondStage/Projects/kbmod/DATA/rerun/diff_warpCompare/deepDiff/{v}/HSC-R2/warps'\n",
    "        reference_fits_images.append(glob.glob(f'{warps_path}/{c}/DIFFEXP*fits')[0])\n",
    "\n",
    "        stamp_files.append(f'{stamps_path}/stamps{gridType}_{c}.pickle')\n",
    "\n",
    "        \n",
    "        ### get the image header and setup a WCS\n",
    "        with fits.open(reference_fits_images[-1]) as han:\n",
    "            header = han[1].header\n",
    "            (A,B) = han[1].data.shape\n",
    "            \n",
    "        im_wcs = wcs.WCS(header)\n",
    "\n",
    "        \n",
    "        ### load the kbmod results\n",
    "        kb_xy = []\n",
    "        if os.path.isfile(f'/media/fraserw/rocketdata/Projects/kbmod/warps_results/{v}/results_{c}_upper_0/results_MERGED.txt'):\n",
    "            #check if the kbmod results from CANFAR are available\n",
    "            with open(f'/media/fraserw/rocketdata/Projects/kbmod/warps_results/{v}/results_{c}_upper_0/results_MERGED.txt') as han:\n",
    "                data = han.readlines()\n",
    "        else:\n",
    "            ### otherwise open a local copy\n",
    "            with open(f'/media/fraserw/rocketdata/Projects/kbmod/warps_results/{v}/results_{c}_lower/results_LOWER.txt') as han:\n",
    "                data = han.readlines()\n",
    "            with open(f'/media/fraserw/rocketdata/Projects/kbmod/warps_results/{v}/results_{c}_upper/results_UPPER.txt') as han:\n",
    "                data += han.readlines()\n",
    "\n",
    "        for ii in range(len(data)):\n",
    "            s = data[ii].split()\n",
    "            x, y = float(s[5]), float(s[7])\n",
    "            repeat = False\n",
    "            for jj in range(len(kb_xy)):\n",
    "                if kb_xy[jj][0]==x and kb_xy[jj][1]==y:\n",
    "                    repeat = True\n",
    "                    break\n",
    "            if not repeat:\n",
    "                kb_xy.append([float(s[5]) , float(s[7]) , float(s[9]), float(s[11]), float(s[1]), 0.0])\n",
    "        kb_xy = np.array(kb_xy)\n",
    "        \n",
    "        ### load the plantlist sources\n",
    "        p_xy = []\n",
    "        if v == '03072':\n",
    "            with open(f'/media/fraserw/rocketdata/Projects/ML_SNS_MOPS/HSC_May25-lsst/rerun/processCcdOutputs/{v}/HSC-R2/corr/planted/CORR-0218606-{c}.plantList') as han:\n",
    "                data = han.readlines()\n",
    "        elif v == '03093':\n",
    "            with open(f'/media/fraserw/rocketdata/Projects/ML_SNS_MOPS/HSC_June19-lsst/rerun/processCcdOutputs/{v}/HSC-R2/corr/planted/CORR-0220262-{c}.plantList') as han:\n",
    "                data = han.readlines()\n",
    "                \n",
    "        for ii in range(1,len(data)):\n",
    "            s = data[ii].split()\n",
    "            ra,dec = float(s[1]), float(s[2])\n",
    "            coord = np.array(im_wcs.all_world2pix(ra, dec, 0))\n",
    "\n",
    "            x,y = coord[0],coord[1]\n",
    "            #x = float(s[3]) + offsets[c][0]\n",
    "            #y = float(s[4]) + offsets[c][1]\n",
    "            repeat = False\n",
    "            for jj in range(len(p_xy)):\n",
    "                if p_xy[jj][0] == x and p_xy[jj][1]==y:\n",
    "                    p_xy[jj][2]-=0.75\n",
    "                    repeat = True\n",
    "\n",
    "            if not repeat:\n",
    "                p_xy.append([x, y, float(s[9]), 0])\n",
    "                \n",
    "        if len(p_xy)>0:\n",
    "            p_xy = np.array(p_xy)\n",
    "            p_xy = p_xy[np.argsort(p_xy[:,2])]\n",
    "            p_xy = p_xy[np.where((p_xy[:,2]>nukeBright)&(p_xy[:,2]<nukeFaint))]\n",
    "\n",
    "            #label the good and bad sources\n",
    "            for ii in range(len(p_xy)):\n",
    "                d = ((p_xy[ii, 0] - kb_xy[:, 0])**2 + (p_xy[ii, 1] - kb_xy[:, 1])**2 )**0.5\n",
    "                args = np.argsort(d)\n",
    "\n",
    "                if d[args[0]]<dist_lim:\n",
    "                    kb_xy[args[0],-1] = p_xy[ii,2]\n",
    "                    #print(kb_xy[args[0]])\n",
    "            #print(p_xy[np.where(p_xy[:,2]>=nukeFaint)])\n",
    "                    \n",
    "        w_bad = np.where(kb_xy[:,-1]==0)\n",
    "        w_good = np.where(kb_xy[:,-1]>0)\n",
    "        print(v, c, len(w_bad[0]), len(w_good[0]), len(kb_xy))\n",
    "\n",
    "        #load the stamps\n",
    "        with open(stamp_files[-1], 'rb') as han:\n",
    "            f = pickle.load(han)\n",
    "        \n",
    "        ### trim to just the best cutout\n",
    "        f = f[:,5,:,:]\n",
    "        ### clip to avoid the crazy min pixel values\n",
    "        f = np.clip(f, -3500., np.max(f))\n",
    "            \n",
    "        n_good = len(w_good[0])\n",
    "        \n",
    "        n_bad_keep = max(1, int(n_good*badGoodRatio))\n",
    "        if n_bad_keep>0:\n",
    "            if not select_bad_at_random:\n",
    "                # sequential selection\n",
    "                step = int(len(w[0])/n_bad_keep)\n",
    "                w = w_bad[0][np.arange(0,len(w_bad[0]),step)]\n",
    "            else:\n",
    "                # random selection\n",
    "                w = w_bad[0][(np.random.rand(n_bad_keep)*len(w_bad[0])).astype(np.int)]\n",
    "\n",
    "        ### add edge bad sources\n",
    "        if bad_edge_enhancement>0:\n",
    "            NN = 0\n",
    "            w_edge = np.where((kb_xy[:, -1] ==0) & ((kb_xy[:,0]<25) | ((B-kb_xy[:,0])<20) | (kb_xy[:, 1]<25) | ((A-kb_xy[:,1])<20)))\n",
    "            n_edge_bad_keep = int(len(w_edge[0])*bad_edge_enhancement)\n",
    "            while NN<n_edge_bad_keep:\n",
    "                j = int(np.random.rand(1)*len(w_edge[0]))\n",
    "                if j not in w:\n",
    "                    w = np.append(w, j)\n",
    "                    NN += 1\n",
    "        n_edge_added+=NN\n",
    "        n_bad_total += len(w)\n",
    "        \n",
    "        w = np.concatenate([w, w_good[0]])\n",
    "        \n",
    "        \n",
    "        print('Number good, bad, and number edge enhanced:', n_good, n_bad_keep, n_edge_bad_keep)\n",
    "\n",
    "        f = f[w]\n",
    "        kb_xy = kb_xy[w]\n",
    "\n",
    "        ### rotate frames\n",
    "        # k should be -rots!\n",
    "        if rots[counter%len(chips)]!=0:\n",
    "            f = np.rot90(f, k=-rots[counter%len(chips)], axes=(1, 2))\n",
    "        counter+=1\n",
    "        \n",
    "        \n",
    "        fs.append(f)\n",
    "        kb_xys.append(kb_xy)\n",
    "        del f, kb_xy\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "source_details = np.concatenate(kb_xys)\n",
    "sns_frames = np.concatenate(fs)\n",
    "print(sns_frames.shape)\n",
    "del kb_xys\n",
    "del fs\n",
    "    \n",
    "print('Number of bad edge sources added:',n_edge_added)\n",
    "print(f'Number of total bad sources in sample {n_bad_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1112.5203 2980.7305\n"
     ]
    }
   ],
   "source": [
    "print(np.min(sns_frames), np.max(sns_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of planted sources in the dataset: 895\n",
      "2.4397674 37.712738\n",
      "Normalized frame min and max: -29.564548 78.97307\n",
      "(2255, 21, 21, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# categorize the sources.\n",
    "# column 0 is bad source. Labelled when ==1\n",
    "# column 1 is good source\n",
    "sns_labels = np.zeros((source_details[:, 5].shape[0], 2), dtype=image_data_type)\n",
    "w = np.where(source_details[:, -1]==0)\n",
    "W = np.where((source_details[:, -1]>0))\n",
    "print('Number of planted sources in the dataset:', len(W[0]))\n",
    "sns_labels[w, 0] = 1.0\n",
    "sns_labels[W, 1] = 1.0\n",
    "\n",
    "\n",
    "if useMedForNans:\n",
    "    med = np.nanmedian(sns_frames)\n",
    "else:\n",
    "    med = 0.0\n",
    "    \n",
    "w_nan = np.where(np.isnan(sns_frames))\n",
    "sns_frames[w_nan] = med\n",
    "\n",
    "(z1, z2) = tzscale.zscale(sns_frames)\n",
    "normer = interval.ManualInterval(z1,z2)\n",
    "\n",
    "mean = np.nanmean(sns_frames)\n",
    "std = np.nanstd(sns_frames)\n",
    "print(mean, std)\n",
    "\n",
    "sns_frames -= mean\n",
    "sns_frames /= std\n",
    "print('Normalized frame min and max:', np.nanmin(sns_frames), np.nanmax(sns_frames))\n",
    "\n",
    "\n",
    "\n",
    "# expand the image data to shape (:, :, :, 1) for the CNN\n",
    "#sns_frames = np.expand_dims(sns_frames, axis=3)\n",
    "sns_frames = np.expand_dims(sns_frames, axis=3)\n",
    "print(sns_frames.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if shuffle_augment:\n",
    "    a = np.copy(sns_frames)\n",
    "    b = np.copy(sns_frames)\n",
    "    c = np.copy(sns_frames)\n",
    "    d = np.copy(sns_frames)\n",
    "    a[:,:-1,:,:] = sns_frames[:,1:,:,:]\n",
    "    b[:,1:,:,:] = sns_frames[:,:-1,:,:]\n",
    "    c[:,:, :-1,:] = sns_frames[:,:,1:,:]\n",
    "    d[:,:, 1:,:] = sns_frames[:,:,:-1,:]\n",
    "    sns_frames = np.concatenate([sns_frames,a,b,c,d])\n",
    "    sns_labels = np.concatenate([sns_labels, np.copy(sns_labels), np.copy(sns_labels), np.copy(sns_labels), np.copy(sns_labels)])\n",
    "    source_details = np.concatenate([source_details, np.copy(source_details), np.copy(source_details), np.copy(source_details), np.copy(source_details)])\n",
    "\n",
    "\n",
    "if double_flip:\n",
    "\n",
    "    sns_frames = np.concatenate([sns_frames, sns_frames[:, ::-1, ::-1, :]])\n",
    "    sns_labels = np.concatenate([sns_labels, sns_labels])\n",
    "    source_details = np.concatenate([source_details, source_details])\n",
    "    \n",
    "    \n",
    "if add_noise:\n",
    "    noise = np.random.normal(0.0, noise_level, sns_frames.shape).astype(image_data_type)\n",
    "    #noised_sns_frames = normed_sns_frames + np.random.normal(0.0, noise_level, normed_sns_frames.shape, dtype=image_data_type)\n",
    "    sns_frames = np.concatenate([sns_frames, sns_frames+noise])\n",
    "    sns_labels = np.concatenate([sns_labels, sns_labels])\n",
    "    source_details = np.concatenate([source_details, source_details])\n",
    "    #del noised_sns_frames\n",
    "    del noise\n",
    "    mean = np.mean(sns_frames)\n",
    "    std = np.std(sns_frames)\n",
    "    print(mean, std)\n",
    "\n",
    "    sns_frames -= mean\n",
    "    sns_frames /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faintest source in dataset: 26.79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Faintest source in dataset:', np.max(source_details[:, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Test/Validation Samples\n",
    "\n",
    "In this part we will split our sample into two; one sample that we will use to train the neural network, aptly named the training sample, and another sample called the test sample. The network will not see the test sample itself during training, but we will use the trained neural network to predict its labels. It will therefore serve as validation to the accuracy of the neural network that has been trained using a different subset of images. We chose to set the size of the test sample as 15% of the total sample, as it is common practice to choose a test sample smaller in size compared to the training sample. It is important to make this split by roughly preserving the ratio of the labels within the total sample. Random splits may cause one of the labels to be underrepresented within training sample, thereby resulting in a neural network inacapable of accurate classifications as it is undertrained in one of the labels. We perform a stratified sampling below to preserve the original ratios of the two morphology types when making the split. \n",
    "\n",
    "I have modified the following to work with my data arrays, not those from the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=1, random_state=410, test_size=0.05,\n",
      "            train_size=None)\n",
      "Number of images in the training sample:  21422\n",
      "Number of objects classified as real in the training sample:  8502\n",
      "Number of objects classified as false in the training sample:  12920\n",
      "\n",
      "Number of images in the test sample:  1128\n",
      "Number of objects classified as real in the validation sample:  448\n",
      "Number of objects classified as false in the validation sample:  680\n",
      "\n",
      "Fraction of bad objects in the training sample 0.603\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Use stratification to split the data into training & test samples.\n",
    "This preserves the ratio of class 0 to class 1 objects when we split the\n",
    "total sample into training and test samples. We choose the test sample to be 15%\n",
    "of the total sample size.\n",
    "\"\"\"\n",
    "\n",
    "skf = StratifiedShuffleSplit(n_splits=1, test_size=test_fraction, random_state=410)\n",
    "print(skf)\n",
    "skf.split(sns_frames, sns_labels)\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(sns_frames, sns_labels):\n",
    "    X_train, X_test = sns_frames[train_index], sns_frames[test_index]\n",
    "    y_train, y_test = sns_labels[train_index], sns_labels[test_index]\n",
    "\n",
    "#del sns_frames\n",
    "\n",
    "\n",
    "print('Number of images in the training sample: ', X_train.shape[0])\n",
    "print('Number of objects classified as real in the training sample: ',\n",
    "      len(np.unique(np.where(y_train == [0, 1])[0])))\n",
    "print('Number of objects classified as false in the training sample: ',\n",
    "      len(np.unique(np.where(y_train == [1, 0])[0])))\n",
    "print()\n",
    "print('Number of images in the test sample: ', X_test.shape[0])\n",
    "print('Number of objects classified as real in the validation sample: ',\n",
    "      len(np.unique(np.where(y_test == [0, 1])[0])))\n",
    "print('Number of objects classified as false in the validation sample: ',\n",
    "      len(np.unique(np.where(y_test == [1, 0])[0])))\n",
    "print()\n",
    "print('Fraction of bad objects in the training sample',\n",
    "      round((np.count_nonzero(y_train == [1, 0])/2)/X_train.shape[0], 3))\n",
    "\n",
    "move_real_to_test = False\n",
    "# remove the real source from the training set as a test to see what happens\n",
    "if args[0] in train_index and move_real_to_test:\n",
    "    w = np.where(train_index == args[0])\n",
    "\n",
    "    print(X_train[w[0], 0, 0, 0])\n",
    "    print(y_train[w[0]])\n",
    "    \n",
    "    X_test = np.concatenate([X_test, X_train[w[0]]])\n",
    "    y_test = np.concatenate([y_test, y_train[w[0]]])\n",
    "    test_index = np.append(test_index, [args[0]], -1)\n",
    "    \n",
    "    X_train = np.concatenate([X_train[:w[0][0]], X_train[w[0][0]+1:]])\n",
    "    y_train = np.concatenate([y_train[:w[0][0]], y_train[w[0][0]+1:]])\n",
    "    train_index = np.concatenate([train_index[:w[0][0]], train_index[w[0][0]+1:]])\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(train_index.shape)\n",
    "    print(X_test.shape)\n",
    "    print(X_train[w[0][0],0, 0, 0])\n",
    "    print(y_train[w[0]])\n",
    "    print()\n",
    "    print(X_test[-1, 0, 0, 0])\n",
    "#w = np.where(train_index == args[0])\n",
    "#y_train[w[0]][0] = 0.0\n",
    "#y_train[w[0]][0] = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of good to bad sources: 0.6580882352941176\n",
      "False weight: 0.5462132352941177\n"
     ]
    }
   ],
   "source": [
    "if useSampleWeights:\n",
    "    n_false_total = len(np.where(y_train[:,0]==1)[0]) + len(np.where(y_test[:,0]==1)[0])\n",
    "    n_true_total = len(np.where(y_train[:,1]==1)[0]) + len(np.where(y_test[:,1]==1)[0])\n",
    "    print('Fraction of good to bad sources:',n_true_total/n_false_total)\n",
    "    \n",
    "    true_weight = 1.0\n",
    "    nominal_false_weight = 0.83\n",
    "    false_weight = n_true_total*nominal_false_weight/n_false_total\n",
    "    print('False weight:' , false_weight)\n",
    "    \n",
    "    train_weight = np.ones(y_train.shape[0], dtype = y_train.dtype)\n",
    "    train_weight[np.where(y_train[:,0]==1)] = false_weight\n",
    "    train_weight[np.where(y_train[:,1]==1)] = true_weight\n",
    "    test_weight = np.ones(y_test.shape[0], dtype = y_train.dtype)\n",
    "    test_weight[np.where(y_test[:,0]==1)] = false_weight\n",
    "    test_weight[np.where(y_test[:,1]==1)] = true_weight\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting the Neural Network Model\n",
    "\n",
    "Here we train the neural network model defined above. The training session will output loss, and accuracy at each epoch. We also plot the progression of the loss and accuracy with respect to training epochs after the training is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble of 5, each with the follwing configuration:\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 21, 21, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 21, 21, 16)        160       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 21, 21, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 10, 32)        4640      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5, 5, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 5, 32)          9248      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 26,722\n",
      "Trainable params: 26,658\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "\n",
      "Training model 1 of 5.\n",
      "...in 23.49548864364624 seconds.\n",
      "\n",
      "Training model 2 of 5.\n",
      "...in 22.23923349380493 seconds.\n",
      "\n",
      "Training model 3 of 5.\n",
      "...in 22.417100191116333 seconds.\n",
      "\n",
      "Training model 4 of 5.\n",
      "...in 22.215118169784546 seconds.\n",
      "\n",
      "Training model 5 of 5.\n",
      "...in 22.310232639312744 seconds.\n",
      "Training completed in 112.68  seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cn_model = convnet_model(X_train.shape[1:], num_models = number_models, dropout_rate = dropout_rate)\n",
    "cn_model.compile(verbose = 1)\n",
    "cn_model.summary()\n",
    "\n",
    "epochs=100\n",
    "if nukeBright==26:\n",
    "    epochs = 200\n",
    "cn_model.train_models_with_one_trainset(X_train, y_train,\n",
    "                                        sample_weights = train_weight,\n",
    "                                        batch_size = batch_size, \n",
    "                                        train_epochs = epochs,\n",
    "                                        verbose = 0)\n",
    "\n",
    "\n",
    "\n",
    "fig = pyl.figure(figsize=(10,3))\n",
    "\n",
    "ax1 = pyl.subplot(121)\n",
    "for k in range(number_models):\n",
    "    ax1.plot(cn_model.classifiers[k].history['accuracy'], color='darkslategray', linewidth=2)\n",
    "ax1.set_title('Model Accuracy')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_xlabel('Epoch')\n",
    "\n",
    "ax2 = pyl.subplot(122)\n",
    "for k in range(number_models):\n",
    "    ax2.plot(cn_model.classifiers[k].history['loss'], color='crimson', linewidth=2)\n",
    "ax2.set_title('Model Loss')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xlabel('Epoch')\n",
    "\n",
    "pyl.show()\n",
    "pyl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-12-291695e8add2>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-291695e8add2>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    cn_model.saveModel(mean,std,save_dir=f'ML_KBmod_modelSave_{nukeBright}_{nukeFaint}_01, random_split_seed=410)\u001b[0m\n\u001b[0m                                                                                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "saveModel = True\n",
    "if saveModel:\n",
    "    cn_model.saveModel(mean,std,save_dir=f'ML_KBmod_modelSave_{nukeBright}_{nukeFaint}_01, random_split_seed=410)\n",
    "    print('saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation\n",
    "\n",
    "Finally, we use the model trained above to make predictions on the test/validation sample. We then compare these predicted labels with the original ones, and derive a prediction accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds_test = cn_model.predict(X_test, verbose=1)\n",
    "\n",
    "preds_train = cn_model.predict(X_train, verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "pyl.figure(figsize=(10,10))\n",
    "pyl.hist(preds_train[:, 1], bins=200, density=True,alpha=0.5, label='Train', log=True)\n",
    "pyl.hist(preds_test[:, 1], bins=200, density=True,alpha=0.5,label='Test', log=True)\n",
    "pyl.legend()\n",
    "pyl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def Eff(m,  eff_max=0.8295, c=0.0054, M_0=26.3803,sig= 0.2016  ):\n",
    "    return (eff_max-c*(m-21.0)**2)/(1+np.exp((m-M_0)/sig))\n",
    "\n",
    "# measure the distribution of p values as a function of magnitude\n",
    "eff_fig = pyl.figure('Efficiency Estimate', figsize=(12, 8))\n",
    "eff_sp = eff_fig.add_subplot(111)\n",
    "eff_sp.set_xlabel('r')\n",
    "eff_sp.set_ylabel('e(r)')\n",
    "                  \n",
    "figure = pyl.figure('P-value histogram', figsize=(12, 12))\n",
    "sp = figure.add_subplot(111)\n",
    "\n",
    "# 0.998 I get 3/36\n",
    "good_p_value = 0.9\n",
    "m_step = 0.25\n",
    "\n",
    "print(len(np.where(preds_test>good_p_value)[0]))\n",
    "\n",
    "bins = np.linspace(0.0,1.0,10000)\n",
    "n_false = bins*0.0\n",
    "n_found = 0.0\n",
    "K = np.sum(np.less(bins,good_p_value))\n",
    "n_bin_diff = 0\n",
    "for m in np.arange(19.,28.,m_step):\n",
    "    # plot the P-value cumulative distributions\n",
    "    w = np.where( ((source_details[test_index, 5]-m)>=0) & ((source_details[test_index, 5]-m)<=m_step) )\n",
    "    p_values = preds_test[w[0],1]\n",
    "    \n",
    "    n = bins*0.0\n",
    "    k = ((p_values-bins[0])/(bins[1]-bins[0])).astype(np.int)\n",
    "    for i in k:\n",
    "        n[i:]+=1.0\n",
    "    n_found+=n[-1]-n[K]\n",
    "    n/=n[-1]\n",
    "    \n",
    "    \n",
    "    # plot the efficiency curve estimate\n",
    "    \n",
    "    sp.plot(bins,n,label=f'{m}<=r<={m+m_step}')\n",
    "    eff_sp.scatter(m+m_step/2.,1.0-n[K])\n",
    "    if len(p_values)>0:\n",
    "        print('{:.2f} {:.4f} {:.4f} {:.2f} {}'.format( m, np.min(p_values), np.max(p_values), 1.0-n[K], n_found-n_bin_diff ))\n",
    "    n_bin_diff = n_found\n",
    "    \n",
    "eff_sp.plot(np.arange(19.,28.,m_step/10.),Eff(np.arange(19.,28.,m_step/10.)))\n",
    "\n",
    "# now sum up the false positives\n",
    "w = np.where( (source_details[test_index, 5])==0) \n",
    "p_values_false = preds_test[w[0],1]\n",
    "\n",
    "k = ((p_values_false-bins[0])/(bins[1]-bins[0])).astype(np.int)\n",
    "for i in k:\n",
    "    n_false[:i]+=1.0\n",
    "\n",
    "print()\n",
    "print(f'Number of false-marked candidates with P>{good_p_value}:',np.sum(n_false[K:]))\n",
    "print(f'Number of sources marked as real with P>{good_p_value}:',n_found)\n",
    "\n",
    "n_false/=n_false[0]\n",
    "pyl.plot(bins, n_false,'k:', lw=4)\n",
    "\n",
    "eff_sp.grid()\n",
    "    \n",
    "pyl.plot([0, 1], [0.1, 0.1], 'k--')\n",
    "pyl.plot([0, 1], [0.3, 0.3], 'k--')\n",
    "pyl.plot([0, 1], [0.5, 0.5], 'k--')\n",
    "pyl.plot([0, 1], [0.7, 0.7], 'k--')\n",
    "pyl.plot([good_p_value, good_p_value], [0, 1], 'k:')\n",
    "sp.legend()\n",
    "sp.set_yscale('log')\n",
    "sp.set_xlim(0.99,1.0)\n",
    "pyl.xlabel('P(is real)')\n",
    "pyl.ylabel('N(p<P)')\n",
    "pyl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter = 0\n",
    "\n",
    "for i, c in enumerate(chips):\n",
    "    for j, v in enumerate(visits):\n",
    "        stamps_path = f'/media/fraserw/rocketdata/Projects/kbmod/stamps/{v}'\n",
    "        warps_path = f'/media/fraserw/SecondStage/Projects/kbmod/DATA/rerun/diff_warpCompare/deepDiff/{v}/HSC-R2/warps'\n",
    "        reference_fits_images.append(glob.glob(f'{warps_path}/{c}/DIFFEXP*fits')[0])\n",
    "\n",
    "        stamp_file = f'{stamps_path}/stamps{gridType}_{c}.pickle'\n",
    "\n",
    "        \n",
    "        ### get the image header and setup a WCS\n",
    "        with fits.open(reference_fits_images[-1]) as han:\n",
    "            header = han[1].header\n",
    "            (A,B) = han[1].data.shape\n",
    "            \n",
    "        im_wcs = wcs.WCS(header)\n",
    "\n",
    "        \n",
    "        ### load the kbmod results\n",
    "        kb_xy = []\n",
    "        if os.path.isfile(f'/media/fraserw/rocketdata/Projects/kbmod/warps_results/{v}/results_{c}_upper_0/results_MERGED.txt'):\n",
    "            #check if the kbmod results from CANFAR are available\n",
    "            with open(f'/media/fraserw/rocketdata/Projects/kbmod/warps_results/{v}/results_{c}_upper_0/results_MERGED.txt') as han:\n",
    "                data = han.readlines()\n",
    "        else:\n",
    "            ### otherwise open a local copy\n",
    "            with open(f'/media/fraserw/rocketdata/Projects/kbmod/warps_results/{v}/results_{c}_lower/results_LOWER.txt') as han:\n",
    "                data = han.readlines()\n",
    "            with open(f'/media/fraserw/rocketdata/Projects/kbmod/warps_results/{v}/results_{c}_upper/results_UPPER.txt') as han:\n",
    "                data += han.readlines()\n",
    "\n",
    "        for ii in range(len(data)):\n",
    "            s = data[ii].split()\n",
    "            x, y = float(s[5]), float(s[7])\n",
    "            repeat = False\n",
    "            for jj in range(len(kb_xy)):\n",
    "                if kb_xy[jj][0]==x and kb_xy[jj][1]==y:\n",
    "                    repeat = True\n",
    "                    break\n",
    "            if not repeat:\n",
    "                kb_xy.append([float(s[5]) , float(s[7]) , float(s[9]), float(s[11]), float(s[1]), 0.0, 0.0])\n",
    "        kb_xy = np.array(kb_xy)\n",
    "        \n",
    "        ### load the plantlist sources\n",
    "        p_xy = []\n",
    "        if v == '03072':\n",
    "            with open(f'/media/fraserw/rocketdata/Projects/ML_SNS_MOPS/HSC_May25-lsst/rerun/processCcdOutputs/{v}/HSC-R2/corr/planted/CORR-0218606-{c}.plantList') as han:\n",
    "                data = han.readlines()\n",
    "        elif v == '03093':\n",
    "            with open(f'/media/fraserw/rocketdata/Projects/ML_SNS_MOPS/HSC_June19-lsst/rerun/processCcdOutputs/{v}/HSC-R2/corr/planted/CORR-0220262-{c}.plantList') as han:\n",
    "                data = han.readlines()\n",
    "                \n",
    "        for ii in range(1,len(data)):\n",
    "            s = data[ii].split()\n",
    "            ra,dec = float(s[1]), float(s[2])\n",
    "            coord = np.array(im_wcs.all_world2pix(ra, dec, 0))\n",
    "\n",
    "            x,y = coord[0],coord[1]\n",
    "            #x = float(s[3]) + offsets[c][0]\n",
    "            #y = float(s[4]) + offsets[c][1]\n",
    "            repeat = False\n",
    "            for jj in range(len(p_xy)):\n",
    "                if p_xy[jj][0] == x and p_xy[jj][1]==y:\n",
    "                    p_xy[jj][2]-=0.75\n",
    "                    repeat = True\n",
    "\n",
    "            if not repeat:\n",
    "                p_xy.append([x, y, float(s[9]), 0])\n",
    "                \n",
    "        if len(p_xy)>0:\n",
    "            p_xy = np.array(p_xy)\n",
    "            p_xy = p_xy[np.argsort(p_xy[:,2])]\n",
    "            p_xy = p_xy[np.where((p_xy[:,2]>nukeBright)&(p_xy[:,2]<nukeFaint))]\n",
    "\n",
    "            #label the good and bad sources\n",
    "            for ii in range(len(p_xy)):\n",
    "                d = ((p_xy[ii, 0] - kb_xy[:, 0])**2 + (p_xy[ii, 1] - kb_xy[:, 1])**2 )**0.5\n",
    "                args = np.argsort(d)\n",
    "\n",
    "                if d[args[0]]<dist_lim:\n",
    "                    kb_xy[args[0],-2] = p_xy[ii,2]\n",
    "                    #print(kb_xy[args[0]])\n",
    "            #print(p_xy[np.where(p_xy[:,2]>=nukeFaint)])\n",
    "         \n",
    "        ### rotate frames\n",
    "        # k should be -rots!\n",
    "        if rots[counter%len(chips)]!=0:\n",
    "            f = np.rot90(f, k=-rots[counter%len(chips)], axes=(1, 2))\n",
    "        counter+=1\n",
    "        \n",
    "        #load the stamps\n",
    "        with open(stamp_files[-1], 'rb') as han:\n",
    "            f = pickle.load(han)\n",
    "        \n",
    "        ### trim to just the best cutout\n",
    "        f = f[:,5,:,:]\n",
    "        ### clip to avoid the crazy min pixel values\n",
    "        f = np.clip(f, -3500., np.max(f))\n",
    "        \n",
    "        f -= mean\n",
    "        f /= std\n",
    "\n",
    "        # expand the image data to shape (:, :, :, 1) for the CNN\n",
    "        #sns_frames = np.expand_dims(sns_frames, axis=3)\n",
    "        f = np.expand_dims(f, axis=3)\n",
    "        preds = cn_model.predict(f, verbose=1)\n",
    "\n",
    "        w = np.where(preds[:, 1]>good_p_value)\n",
    "        print(len(w[0]), len(f))\n",
    "        #for k in w[0]:\n",
    "        #    kb_xy[k,-1]=1.0\n",
    "        #    print(kb_xy[k])\n",
    "        break\n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
